Our dad has a stutter, growing up it has just become something we became used to. We don’t even notice it until moments where the GPS in our car doesn’t recognize the location he’s saying, or when Alexa doesn’t understand to skip to the next song. These moments abruptly highlight that the same technologies that make our lives so much more efficient, make others’ much more difficult. We want the millions of people who express themselves with atypical speech, whether it’s a stutter, long pauses, or uncharacteristic tone, to have the same ability to interact with the technology that enables so much in our lives. The main issue behind the inability for software like Alexa and Siri to recognise diverse speech is lack of training data. This is where RepME comes in. RepME will allow individuals to finally have their voices recognized and enable accessibility through speech recognition software by producing a good dataset that tech companies can reliably use to train their software. As a team, we overcame challenges associated with building our demo website - as none of us came from a computer science background. We demonstrated our solution though developing a proof-of-concept application - RepME. A community driven social media campaign will allow real individuals with diverse speech patterns to upload snippets of their voice. This voice data will then be used to train specific type AI algorithm called generative adversarial networks which can then generate a database of computer-generated diverse voices while protecting the privacy of individuals. This database will serve as a resource for tech companies that work in voice recognition software to finally allow their service to be accessible to all.